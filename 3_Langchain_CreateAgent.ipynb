{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1063e32",
   "metadata": {},
   "source": "# ü¶ú LangChain `create_agent`: High-Level Agent Development - Interactive Demo\n\n**Welcome to the high-level agent development demonstration!**\n\nIn the previous notebook, we built a graph manually (defining nodes, edges, and state) using LangGraph. That approach gave us complete control but required substantial setup and boilerplate code.\n\nThis notebook introduces **`create_agent`**, a high-level function from the `langchain` module that dramatically simplifies agent creation.\n\n## üí° What is `create_agent`?\n\n`create_agent` is a **pre-assembled LangGraph** - a production-ready agent template that handles all the common patterns automatically.\n\nUnder the hood, `create_agent` automatically:\n1. Creates a `StateGraph` with proper state management\n2. Adds a model node for reasoning (LLM calls)\n3. Adds a tool node for executing actions\n4. Connects them with the correct edges and loops\n5. Compiles it into a ready-to-use `CompiledGraph`\n\n**The result?** You get the same powerful agent capabilities with ~80% less code.\n\n## üìö What This Demo Covers\n\n### **1. `create_agent` Function**\nInstantiating a pre-built ReAct (Reasoning + Acting) agent workflow without manually defining nodes and edges.\n\n### **2. Standard Interrupts**\nHandling missing information by pausing agent execution (same pattern as before, but with less code).\n\n### **3. Middleware Integration**\nA powerful way to add cross-cutting concerns to your agent - like human approval steps, logging, monitoring, or validation - without modifying the core agent logic.\n\n---\n\n## üéØ When to Use `create_agent` vs Manual Graphs\n\n**Use `create_agent` when:**\n- You need a standard ReAct agent (reason ‚Üí act ‚Üí reason ‚Üí act loop)\n- You want rapid prototyping and development\n- Your use case fits the common agent pattern\n- You prefer less boilerplate code\n\n**Build manual graphs when:**\n- You need custom workflow logic beyond ReAct\n- You require specialized routing or conditional logic\n- You're implementing novel agent architectures\n- You need fine-grained control over every step\n\n---\n\n**This demo shows you:**\n- How to create production-ready agents in just a few lines\n- The abstraction layers that LangChain provides\n- Adding middleware for approval workflows\n- Understanding what's happening under the hood"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c2ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langraph_prompts import ACTION_PROMPT_TEMPLATE\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command, interrupt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a809e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_time_off_balance(user_id: str) -> int:\n",
    "    '''\n",
    "    Get the time off balance for a user. \n",
    "\n",
    "    Args :\n",
    "        user_id: A unique string representing the user id\n",
    "\n",
    "    Returns:\n",
    "        An integer value representing the time-off balance\n",
    "    '''\n",
    "    return 10\n",
    "\n",
    "@tool\n",
    "def process_time_off(user_id: str, start_date: str, end_date: str) -> dict:\n",
    "    '''\n",
    "    Process time-off request for a user\n",
    "\n",
    "    Args :\n",
    "        user_id: A unique string representing the user id\n",
    "        start_date: A date string in YYYY-MM-DD format for the start date of the time-off request\n",
    "        end_date: A date string in YYYY-MM-DD format for the end date of the time-off request\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the following keys:\n",
    "        - status: A string value representing the status of the time-off request\n",
    "        - message: A string value representing the message of the time-off request\n",
    "    '''\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    days_requested = end_date - start_date\n",
    "    time_off_balance = get_time_off_balance.invoke({\"user_id\": user_id})\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    if days_requested.days + 1 > time_off_balance:\n",
    "        result['status'] = 'error'\n",
    "        result['message'] = f'Time off request failed. you only have {time_off_balance} days of remaining leaves but requested {days_requested.days} days'\n",
    "\n",
    "    else:\n",
    "        time_off_balance -= days_requested.days + 1\n",
    "        result['status'] = 'success'\n",
    "        result['message'] = f'Time off request processed successfully for {days_requested.days + 1} days. Your remaining time off balance is {time_off_balance}'\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_additional_info_from_human( message: str) -> str:\n",
    "    '''\n",
    "        Raises an interrupt to fetch additional information from the human requesting the action\n",
    "\n",
    "        Args:\n",
    "            message: a message string from the AI requesting the user for missing information\n",
    "\n",
    "        Returns:\n",
    "            A string value representing the response with additional information from the human\n",
    "\n",
    "    '''\n",
    "    interrupt_result = interrupt(message)\n",
    "\n",
    "    return interrupt_result['user_message']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6120ad",
   "metadata": {},
   "source": [
    "## 1) Creating the Agent (The Easy Way)\n",
    "\n",
    "* **Manual Graph (Previous Notebook):** Like building a PC from scratch. You buy the CPU, RAM, and Motherboard, and connect the wires yourself. It's powerful but takes time.\n",
    "* **`create_agent` (This Notebook):** Like buying a pre-built laptop. You just turn it on. It has the same components inside (LLM, Tools, Memory), but LangChain assembled them for you.\n",
    "\n",
    "###  Code Context\n",
    "In the code below:\n",
    "* `create_agent(...)`: This single function replaces the `StateGraph`, `add_node`, `add_edge`, and `compile` steps.\n",
    "* It automatically creates a graph where the LLM decides to call tools and loops back until it's done.\n",
    "* `checkpointer=InMemorySaver()`: We still need this to enable \"Pause/Resume\" functionality.\n",
    "\n",
    "üìö **[Docs: create_agent](https://docs.langchain.com/oss/python/langchain/agents)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981e7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '1' \n",
    "llm = init_chat_model(model=\"gpt-4o\", temperature=0)\n",
    "tools = [get_time_off_balance, process_time_off, get_additional_info_from_human]\n",
    "\n",
    "todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=ACTION_PROMPT_TEMPLATE).invoke({'todays_date': todays_date, 'user_id': user_id})\n",
    "\n",
    "agent = create_agent(llm, tools=tools, system_prompt = system_prompt.text, checkpointer=InMemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be36f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"I want to take leave\"\n",
    "\n",
    "config = {'configurable': {'thread_id': user_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823efd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave', additional_kwargs={}, response_metadata={}, id='c355c23c-c91b-402d-a7e6-94c690d1a38f'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 343, 'total_tokens': 373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CnivJGhc2gsHzYnvc3ln0qKjlBpnn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d8947638-b088-48f5-989a-a121c0fe47a9-0', tool_calls=[{'name': 'get_additional_info_from_human', 'args': {'message': 'Please provide the start and end dates for your leave request.'}, 'id': 'call_yMFLQx6Cjxz6NGOwfwOPk6G3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 30, 'total_tokens': 373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " '__interrupt__': [Interrupt(value='Please provide the start and end dates for your leave request.', id='b608e27a9acde56f5d5cd7c0d9303984')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_message}]}, config=config)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153da9a",
   "metadata": {},
   "source": [
    "## 1.1) Resuming the Agent\n",
    "\n",
    "Just like in the previous notebook, our `get_additional_info_from_human` tool triggered an **Interrupt**. The agent is now paused, waiting for the \"End Date\".\n",
    "We use the same `Command(resume=...)` pattern to provide the answer and un-pause execution.\n",
    "\n",
    "### Code Context\n",
    "In the code below:\n",
    "* `agent.invoke(...)`: We pass the `Command` object with the user's answer (`\"tomorrow\"`).\n",
    "* The agent takes this answer, pretends the tool returned it, and continues its logic to book the leave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b705e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave', additional_kwargs={}, response_metadata={}, id='c355c23c-c91b-402d-a7e6-94c690d1a38f'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 343, 'total_tokens': 373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CnivJGhc2gsHzYnvc3ln0qKjlBpnn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d8947638-b088-48f5-989a-a121c0fe47a9-0', tool_calls=[{'name': 'get_additional_info_from_human', 'args': {'message': 'Please provide the start and end dates for your leave request.'}, 'id': 'call_yMFLQx6Cjxz6NGOwfwOPk6G3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 30, 'total_tokens': 373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='tomorrow', name='get_additional_info_from_human', id='1a5fef6b-e48f-47d5-a67b-91a6e458d160', tool_call_id='call_yMFLQx6Cjxz6NGOwfwOPk6G3'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 388, 'total_tokens': 424, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniwLCtzavzUhx0RZODyq9Whgl7RQ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--2f60e64e-5a3c-45f2-8e8a-273ccd3d8dbf-0', tool_calls=[{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'id': 'call_OqjboY50UqJujEUp7TgmeKQa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 388, 'output_tokens': 36, 'total_tokens': 424, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\"status\": \"success\", \"message\": \"Time off request processed successfully for 1 days. Your remaining time off balance is 9\"}', name='process_time_off', id='09aebedb-625e-459a-a4ca-2f589c1a07e4', tool_call_id='call_OqjboY50UqJujEUp7TgmeKQa'),\n",
       "  AIMessage(content='Your time off request for December 18, 2025, has been processed successfully for 1 day. Your remaining time off balance is 9 days.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 462, 'total_tokens': 495, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniwMbBm9PkhreIXoNZO1zyxg3LlB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0b8817fc-08f2-4306-b0c1-01e1d56fec7b-0', usage_metadata={'input_tokens': 462, 'output_tokens': 33, 'total_tokens': 495, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message = \"tomorrow\"\n",
    "\n",
    "result = agent.invoke(Command(resume={'user_message': user_message}), config=config)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc47db",
   "metadata": {},
   "source": [
    "## 3) Middleware (Human-in-the-Loop)\n",
    "\n",
    "Middleware in LangChain is a new abstraction that lets you hook into and control the agent‚Äôs core loop at defined points (before the model is called, as the model is called, and after the model/tool step finishes). It is conceptually similar to HTTP middleware in web frameworks: you can stack multiple middleware components that each inspect or modify state as a request ‚Äúflows‚Äù through the agent.\n",
    "\n",
    "Each middleware can read and modify the agent state, messages, tools, or model configuration at specific hook points, without changing the agent implementation itself.\n",
    "\n",
    "In our code, we are adding this \"Are you sure?\" popup to the **Book Leave** tool to prevent accidental bookings.\n",
    "\n",
    "### Code Context\n",
    "In the code below:\n",
    "* `HumanInTheLoopMiddleware`: This is the component that intercepts tool calls.\n",
    "* `interrupt_on`: This dictionary defines **which** tools trigger the pause. We map `process_time_off` to specific permissions, ensuring the agent cannot run this specific tool without external approval.\n",
    "\n",
    "üìö **[Docs: Middleware](https://docs.langchain.com/oss/python/langchain/middleware/overview)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1086e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170281da",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_middleware = create_agent(llm, \n",
    "    tools=tools, \n",
    "    system_prompt = system_prompt.text, \n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"process_time_off\": {\n",
    "                    \"allowed_decisions\": [\"approve\", \"reject\"],\n",
    "                },\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da406938",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"I want to take leave on 18-12-2025\"\n",
    "config = {'configurable': {'thread_id': user_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e703a3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave on 18-12-2025', additional_kwargs={}, response_metadata={}, id='daa87b56-6071-4941-b255-5883aab7e071'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 351, 'total_tokens': 368, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniyfSrVNGRtisDKCODKVYuxgmDId', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f372138d-5167-4cd2-8c06-c0ba796c6d1a-0', tool_calls=[{'name': 'get_time_off_balance', 'args': {'user_id': '1'}, 'id': 'call_zaRF0AS9LoxXP2QGjRsYI0aB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 17, 'total_tokens': 368, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='10', name='get_time_off_balance', id='ce1dd760-8f7f-4156-b707-e5355d7e8e7e', tool_call_id='call_zaRF0AS9LoxXP2QGjRsYI0aB'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 379, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-Cniygl1CyLgHA58v6rXE8W5f6HPDm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--205bbe6e-9993-4dbc-9336-aaec71fa0bb3-0', tool_calls=[{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'id': 'call_Y27odQNbCz0GBVsSXgNZQKnH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 36, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'description': \"Tool execution requires approval\\n\\nTool: process_time_off\\nArgs: {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}\"}], 'review_configs': [{'action_name': 'process_time_off', 'allowed_decisions': ['approve', 'reject']}]}, id='c0b3cc7785c4ad2cc0342fa2300d278a')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_middleware.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_message}]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b93c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave on 18-12-2025', additional_kwargs={}, response_metadata={}, id='daa87b56-6071-4941-b255-5883aab7e071'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 351, 'total_tokens': 368, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniyfSrVNGRtisDKCODKVYuxgmDId', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f372138d-5167-4cd2-8c06-c0ba796c6d1a-0', tool_calls=[{'name': 'get_time_off_balance', 'args': {'user_id': '1'}, 'id': 'call_zaRF0AS9LoxXP2QGjRsYI0aB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 17, 'total_tokens': 368, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='10', name='get_time_off_balance', id='ce1dd760-8f7f-4156-b707-e5355d7e8e7e', tool_call_id='call_zaRF0AS9LoxXP2QGjRsYI0aB'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 379, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-Cniygl1CyLgHA58v6rXE8W5f6HPDm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--205bbe6e-9993-4dbc-9336-aaec71fa0bb3-0', tool_calls=[{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'id': 'call_Y27odQNbCz0GBVsSXgNZQKnH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 36, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\"status\": \"success\", \"message\": \"Time off request processed successfully for 1 days. Your remaining time off balance is 9\"}', name='process_time_off', id='39063f04-3fc7-4b6a-9b68-e75c42c83d60', tool_call_id='call_Y27odQNbCz0GBVsSXgNZQKnH'),\n",
       "  AIMessage(content='Your time-off request for December 18, 2025, has been processed successfully. You have 9 days of time-off balance remaining.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 453, 'total_tokens': 483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniyuB1GGYRbDW88DsluC0AwShk2n', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4bc42599-1293-495d-a620-985e2455576e-0', usage_metadata={'input_tokens': 453, 'output_tokens': 30, 'total_tokens': 483, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_middleware.invoke(Command(resume={\"decisions\": [{\"type\": \"approve\"}]}), config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}