{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1063e32",
   "metadata": {},
   "source": [
    "# ü¶úLangChain `create_agent`\n",
    "\n",
    "**Welcome!**\n",
    "In the previous notebook, we built a graph manually (nodes, edges, state) using LangGraph. That gave us total control but required a lot of setup.\n",
    "This notebook introduces **`create_agent`**, a high-level function from the `langchain` module.\n",
    "\n",
    "###  What is `create_agent`?\n",
    "It is a **pre-assembled LangGraph**.\n",
    "Under the hood, `create_agent` automatically:\n",
    "1.  Creates a `StateGraph`.\n",
    "2.  Adds a model node and a tool node.\n",
    "3.  Connects them with the correct edges (loops).\n",
    "4.  Compiles it into a `CompiledGraph`.\n",
    "\n",
    "### **üìö What We Will Cover**\n",
    "1.  **`create_agent`:** Instantiating a pre-built ReAct agent workflow (Model + Tools loop) without needing to define nodes and edges manually.\n",
    "2.  **Standard Interrupts:** Handling missing info (just like before).\n",
    "3.  **Middleware:** A way to hook into the agent's brain to modify its behavior (e.g., adding a \"Human Approval\" step before dangerous tools are run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c2ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langraph_prompts import ACTION_PROMPT_TEMPLATE\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command, interrupt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a809e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_time_off_balance(user_id: str) -> int:\n",
    "    '''\n",
    "    Get the time off balance for a user. \n",
    "\n",
    "    Args :\n",
    "        user_id: A unique string representing the user id\n",
    "\n",
    "    Returns:\n",
    "        An integer value representing the time-off balance\n",
    "    '''\n",
    "    return 10\n",
    "\n",
    "@tool\n",
    "def process_time_off(user_id: str, start_date: str, end_date: str) -> dict:\n",
    "    '''\n",
    "    Process time-off request for a user\n",
    "\n",
    "    Args :\n",
    "        user_id: A unique string representing the user id\n",
    "        start_date: A date string in YYYY-MM-DD format for the start date of the time-off request\n",
    "        end_date: A date string in YYYY-MM-DD format for the end date of the time-off request\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the following keys:\n",
    "        - status: A string value representing the status of the time-off request\n",
    "        - message: A string value representing the message of the time-off request\n",
    "    '''\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    days_requested = end_date - start_date\n",
    "    time_off_balance = get_time_off_balance.invoke({\"user_id\": user_id})\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    if days_requested.days + 1 > time_off_balance:\n",
    "        result['status'] = 'error'\n",
    "        result['message'] = f'Time off request failed. you only have {time_off_balance} days of remaining leaves but requested {days_requested.days} days'\n",
    "\n",
    "    else:\n",
    "        time_off_balance -= days_requested.days + 1\n",
    "        result['status'] = 'success'\n",
    "        result['message'] = f'Time off request processed successfully for {days_requested.days + 1} days. Your remaining time off balance is {time_off_balance}'\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_additional_info_from_human( message: str) -> str:\n",
    "    '''\n",
    "        Raises an interrupt to fetch additional information from the human requesting the action\n",
    "\n",
    "        Args:\n",
    "            message: a message string from the AI requesting the user for missing information\n",
    "\n",
    "        Returns:\n",
    "            A string value representing the response with additional information from the human\n",
    "\n",
    "    '''\n",
    "    interrupt_result = interrupt(message)\n",
    "\n",
    "    return interrupt_result['user_message']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6120ad",
   "metadata": {},
   "source": [
    "## 1) Creating the Agent (The Easy Way)\n",
    "\n",
    "* **Manual Graph (Previous Notebook):** Like building a PC from scratch. You buy the CPU, RAM, and Motherboard, and connect the wires yourself. It's powerful but takes time.\n",
    "* **`create_agent` (This Notebook):** Like buying a pre-built laptop. You just turn it on. It has the same components inside (LLM, Tools, Memory), but LangChain assembled them for you.\n",
    "\n",
    "###  Code Context\n",
    "In the code below:\n",
    "* `create_agent(...)`: This single function replaces the `StateGraph`, `add_node`, `add_edge`, and `compile` steps.\n",
    "* It automatically creates a graph where the LLM decides to call tools and loops back until it's done.\n",
    "* `checkpointer=InMemorySaver()`: We still need this to enable \"Pause/Resume\" functionality.\n",
    "\n",
    "üìö **[Docs: create_agent](https://docs.langchain.com/oss/python/langchain/agents)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981e7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '1' \n",
    "llm = init_chat_model(model=\"gpt-4o\", temperature=0)\n",
    "tools = [get_time_off_balance, process_time_off, get_additional_info_from_human]\n",
    "\n",
    "todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=ACTION_PROMPT_TEMPLATE).invoke({'todays_date': todays_date, 'user_id': user_id})\n",
    "\n",
    "agent = create_agent(llm, tools=tools, system_prompt = system_prompt.text, checkpointer=InMemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be36f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"I want to take leave\"\n",
    "\n",
    "config = {'configurable': {'thread_id': user_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823efd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave', additional_kwargs={}, response_metadata={}, id='c355c23c-c91b-402d-a7e6-94c690d1a38f'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 343, 'total_tokens': 373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CnivJGhc2gsHzYnvc3ln0qKjlBpnn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d8947638-b088-48f5-989a-a121c0fe47a9-0', tool_calls=[{'name': 'get_additional_info_from_human', 'args': {'message': 'Please provide the start and end dates for your leave request.'}, 'id': 'call_yMFLQx6Cjxz6NGOwfwOPk6G3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 30, 'total_tokens': 373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " '__interrupt__': [Interrupt(value='Please provide the start and end dates for your leave request.', id='b608e27a9acde56f5d5cd7c0d9303984')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_message}]}, config=config)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153da9a",
   "metadata": {},
   "source": [
    "## 1.1) Resuming the Agent\n",
    "\n",
    "Just like in the previous notebook, our `get_additional_info_from_human` tool triggered an **Interrupt**. The agent is now paused, waiting for the \"End Date\".\n",
    "We use the same `Command(resume=...)` pattern to provide the answer and un-pause execution.\n",
    "\n",
    "### Code Context\n",
    "In the code below:\n",
    "* `agent.invoke(...)`: We pass the `Command` object with the user's answer (`\"tomorrow\"`).\n",
    "* The agent takes this answer, pretends the tool returned it, and continues its logic to book the leave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b705e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave', additional_kwargs={}, response_metadata={}, id='c355c23c-c91b-402d-a7e6-94c690d1a38f'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 343, 'total_tokens': 373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CnivJGhc2gsHzYnvc3ln0qKjlBpnn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d8947638-b088-48f5-989a-a121c0fe47a9-0', tool_calls=[{'name': 'get_additional_info_from_human', 'args': {'message': 'Please provide the start and end dates for your leave request.'}, 'id': 'call_yMFLQx6Cjxz6NGOwfwOPk6G3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 30, 'total_tokens': 373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='tomorrow', name='get_additional_info_from_human', id='1a5fef6b-e48f-47d5-a67b-91a6e458d160', tool_call_id='call_yMFLQx6Cjxz6NGOwfwOPk6G3'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 388, 'total_tokens': 424, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniwLCtzavzUhx0RZODyq9Whgl7RQ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--2f60e64e-5a3c-45f2-8e8a-273ccd3d8dbf-0', tool_calls=[{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'id': 'call_OqjboY50UqJujEUp7TgmeKQa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 388, 'output_tokens': 36, 'total_tokens': 424, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\"status\": \"success\", \"message\": \"Time off request processed successfully for 1 days. Your remaining time off balance is 9\"}', name='process_time_off', id='09aebedb-625e-459a-a4ca-2f589c1a07e4', tool_call_id='call_OqjboY50UqJujEUp7TgmeKQa'),\n",
       "  AIMessage(content='Your time off request for December 18, 2025, has been processed successfully for 1 day. Your remaining time off balance is 9 days.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 462, 'total_tokens': 495, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniwMbBm9PkhreIXoNZO1zyxg3LlB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0b8817fc-08f2-4306-b0c1-01e1d56fec7b-0', usage_metadata={'input_tokens': 462, 'output_tokens': 33, 'total_tokens': 495, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message = \"tomorrow\"\n",
    "\n",
    "result = agent.invoke(Command(resume={'user_message': user_message}), config=config)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc47db",
   "metadata": {},
   "source": [
    "## 3) Middleware (Human-in-the-Loop)\n",
    "\n",
    "Middleware in LangChain is a new abstraction that lets you hook into and control the agent‚Äôs core loop at defined points (before the model is called, as the model is called, and after the model/tool step finishes). It is conceptually similar to HTTP middleware in web frameworks: you can stack multiple middleware components that each inspect or modify state as a request ‚Äúflows‚Äù through the agent.\n",
    "\n",
    "Each middleware can read and modify the agent state, messages, tools, or model configuration at specific hook points, without changing the agent implementation itself.\n",
    "\n",
    "In our code, we are adding this \"Are you sure?\" popup to the **Book Leave** tool to prevent accidental bookings.\n",
    "\n",
    "### Code Context\n",
    "In the code below:\n",
    "* `HumanInTheLoopMiddleware`: This is the component that intercepts tool calls.\n",
    "* `interrupt_on`: This dictionary defines **which** tools trigger the pause. We map `process_time_off` to specific permissions, ensuring the agent cannot run this specific tool without external approval.\n",
    "\n",
    "üìö **[Docs: Middleware](https://docs.langchain.com/oss/python/langchain/middleware/overview)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1086e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170281da",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_middleware = create_agent(llm, \n",
    "    tools=tools, \n",
    "    system_prompt = system_prompt.text, \n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"process_time_off\": {\n",
    "                    \"allowed_decisions\": [\"approve\", \"reject\"],\n",
    "                },\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da406938",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"I want to take leave on 18-12-2025\"\n",
    "config = {'configurable': {'thread_id': user_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e703a3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave on 18-12-2025', additional_kwargs={}, response_metadata={}, id='daa87b56-6071-4941-b255-5883aab7e071'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 351, 'total_tokens': 368, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniyfSrVNGRtisDKCODKVYuxgmDId', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f372138d-5167-4cd2-8c06-c0ba796c6d1a-0', tool_calls=[{'name': 'get_time_off_balance', 'args': {'user_id': '1'}, 'id': 'call_zaRF0AS9LoxXP2QGjRsYI0aB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 17, 'total_tokens': 368, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='10', name='get_time_off_balance', id='ce1dd760-8f7f-4156-b707-e5355d7e8e7e', tool_call_id='call_zaRF0AS9LoxXP2QGjRsYI0aB'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 379, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-Cniygl1CyLgHA58v6rXE8W5f6HPDm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--205bbe6e-9993-4dbc-9336-aaec71fa0bb3-0', tool_calls=[{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'id': 'call_Y27odQNbCz0GBVsSXgNZQKnH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 36, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'description': \"Tool execution requires approval\\n\\nTool: process_time_off\\nArgs: {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}\"}], 'review_configs': [{'action_name': 'process_time_off', 'allowed_decisions': ['approve', 'reject']}]}, id='c0b3cc7785c4ad2cc0342fa2300d278a')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_middleware.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_message}]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b93c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to take leave on 18-12-2025', additional_kwargs={}, response_metadata={}, id='daa87b56-6071-4941-b255-5883aab7e071'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 351, 'total_tokens': 368, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniyfSrVNGRtisDKCODKVYuxgmDId', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f372138d-5167-4cd2-8c06-c0ba796c6d1a-0', tool_calls=[{'name': 'get_time_off_balance', 'args': {'user_id': '1'}, 'id': 'call_zaRF0AS9LoxXP2QGjRsYI0aB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 351, 'output_tokens': 17, 'total_tokens': 368, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='10', name='get_time_off_balance', id='ce1dd760-8f7f-4156-b707-e5355d7e8e7e', tool_call_id='call_zaRF0AS9LoxXP2QGjRsYI0aB'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 379, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-Cniygl1CyLgHA58v6rXE8W5f6HPDm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--205bbe6e-9993-4dbc-9336-aaec71fa0bb3-0', tool_calls=[{'name': 'process_time_off', 'args': {'user_id': '1', 'start_date': '2025-12-18', 'end_date': '2025-12-18'}, 'id': 'call_Y27odQNbCz0GBVsSXgNZQKnH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 36, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\"status\": \"success\", \"message\": \"Time off request processed successfully for 1 days. Your remaining time off balance is 9\"}', name='process_time_off', id='39063f04-3fc7-4b6a-9b68-e75c42c83d60', tool_call_id='call_Y27odQNbCz0GBVsSXgNZQKnH'),\n",
       "  AIMessage(content='Your time-off request for December 18, 2025, has been processed successfully. You have 9 days of time-off balance remaining.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 453, 'total_tokens': 483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e1dc348028', 'id': 'chatcmpl-CniyuB1GGYRbDW88DsluC0AwShk2n', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--4bc42599-1293-495d-a620-985e2455576e-0', usage_metadata={'input_tokens': 453, 'output_tokens': 30, 'total_tokens': 483, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_middleware.invoke(Command(resume={\"decisions\": [{\"type\": \"approve\"}]}), config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
